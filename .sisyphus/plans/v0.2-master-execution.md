# Master Execution Plan â€” yt-recorder v0.2

> **One-shot executable. Each TODO is atomic, committed separately.**
> **Agent session refs**: W1-2=ses_378dad0b, W3=ses_378da46b, W4-5=ses_378d9cf4, W6-7=ses_378d93c9, W8-9=ses_378d8a51

---

## Execution Order (critical path bolded)

```
**W1.1** â†’ **W1.2** â†’ **W2.1** â†’ W2.2 + W2.3 (parallel)
                         â†“
                       **W3.1** â†’ **W3.2** â†’ **W3.3**
                                                â†“
                                    **W4.1** â†’ **W4.2** â†’ W5.1 â†’ W5.2
                                                              â†“
                                                W6.1 + W6.2 + W6.3 (parallel)
                                                              â†“
                                                      W7.1 + W7.2 (parallel)
                                                              â†“
                                                      W8.1 + W8.2 (parallel)
                                                              â†“
                                                W9.1 + W9.2 + W9.3 (parallel)
```

---

## Global Constraints (apply to ALL tasks)

- Python 3.9 â€” no `match`, use `from __future__ import annotations` for `X | Y`
- `mypy --strict`, `ruff check`, `ruff format --check` must pass after EVERY commit
- Pre-commit hooks: ruff + mypy
- Domain layer: ZERO adapter imports
- All YouTube selectors in `constants.py`
- Frozen dataclasses â†’ new instances for updates, never mutate
- Test pattern: `pytest + unittest.mock.Mock()` auto-attributes
- Commits: concise, sacrifice grammar

---

## Wave 1 â€” Stabilize

### W1.1: Commit upload flow fixes
```
Files: src/yt_recorder/adapters/youtube.py, tests/test_youtube.py
Action: git add -A && git commit && git push
Commit: "fix: upload flow â€” domcontentloaded, wait_for_function Done btn, dialog close"
Verify: pytest tests/test_youtube.py && mypy --strict src && ruff check src tests
```

### W1.2: Move playlist selectors to constants.py

**constants.py** â€” append after UPLOAD_TIMEOUT_SECONDS:
```python
# Playlist assignment selectors (YouTube Studio edit page)
PLAYLIST_DROPDOWN = 'tp-yt-paper-button[aria-label*="Playlist"]'
PLAYLIST_OPTION_TEMPLATE = "tp-yt-paper-item:has-text('{name}')"
PLAYLIST_SAVE = "tp-yt-button-shape[aria-label='Save']"
```

**youtube.py** assign_playlist() â€” replace inline strings:
```python
# Line 219: replace literal with constants.PLAYLIST_DROPDOWN
# Line 227-228: replace literal with constants.PLAYLIST_OPTION_TEMPLATE.format(name=playlist_name)
# Line 237: replace literal with constants.PLAYLIST_SAVE
```

```
Verify: pytest tests/test_youtube.py && mypy --strict src && ruff check src tests
Commit: "refactor: centralize playlist selectors in constants.py"
```

---

## Wave 2 â€” Foundation

### W2.1: Create domain/protocols.py

**New file**: `src/yt_recorder/domain/protocols.py`
```python
"""Port interfaces for the hexagonal architecture.

Adapters implement these via structural typing (duck typing).
Pipeline depends on these, never on concrete adapter classes.
"""
from __future__ import annotations

from pathlib import Path
from typing import Protocol, runtime_checkable

from yt_recorder.domain.models import RegistryEntry, UploadResult


@runtime_checkable
class VideoUploader(Protocol):
    """Single-account video upload + playlist assignment."""

    def open(self) -> None: ...
    def close(self) -> None: ...
    def upload(self, path: Path, title: str) -> UploadResult: ...
    def assign_playlist(self, video_id: str, playlist_name: str) -> bool: ...


@runtime_checkable
class TranscriptFetcher(Protocol):
    """Transcript extraction from uploaded videos."""

    def fetch(self, video_id: str, lang: str = ...) -> Path: ...


@runtime_checkable
class RegistryStore(Protocol):
    """Persistent registry for video metadata.

    Note: update_transcript accepts `str` (not bool) â€” TranscriptStatus(str, Enum)
    satisfies this because it IS a str. Forward-compatible with Wave 3.
    """

    def load(self) -> list[RegistryEntry]: ...
    def append(self, entry: RegistryEntry) -> None: ...
    def update_transcript(self, file: str, status: str) -> None: ...
    def update_account_id(self, file: str, account: str, video_id: str) -> None: ...
```

**Key decisions**:
- `assign_playlist -> bool` from day 1 (forward-compatible for W5)
- `update_transcript(status: str)` not `bool` (forward-compatible for W3)
- `TranscriptFetcher.fetch` uses `lang: str = ...` (Ellipsis = default in Protocol)
- No `FileScanner` protocol â€” it's a plain function, not worth abstracting
- `runtime_checkable` enables `isinstance` checks in tests

```
Verify: mypy --strict src
Commit: "feat: adapter Protocol interfaces in domain layer"
```

### W2.2: Pipeline depends on Protocols (parallel with W2.3)

**pipeline.py** changes:
```python
# REMOVE these imports from __init__ type hints:
# (keep them in from_directory only)

# ADD:
from yt_recorder.domain.protocols import RegistryStore, TranscriptFetcher

# __init__ signature:
def __init__(
    self,
    config: Config,
    registry: RegistryStore,          # was: MarkdownRegistryStore
    raid: RaidAdapter,                 # stays concrete (orchestrator)
    transcriber: TranscriptFetcher | None = None,  # was: YtdlpTranscriptAdapter
):

# from_directory() keeps concrete imports (it's the composition root)
```

**Gotcha**: `pipeline.py` calls `self.transcriber.extract_cookies()` at line 248. This is NOT on TranscriptFetcher protocol. Solutions:
- Move `extract_cookies` call to `from_directory()` factory (before constructing pipeline)
- OR add `extract_cookies` to protocol
- **Best**: Move to factory. Pipeline shouldn't know about cookie extraction.

```python
# from_directory() change:
@classmethod
def from_directory(cls, directory: Path, with_transcriber: bool = False) -> RecordingPipeline:
    config = load_config()
    account_names = [a.name for a in config.accounts]
    registry = MarkdownRegistryStore(directory / "registry.md", account_names)
    raid = RaidAdapter(config.accounts, config.headless, config.delays)
    transcriber = None
    if with_transcriber and config.accounts:
        t = YtdlpTranscriptAdapter(
            cookies_path=config.accounts[0].cookies_path,
            output_dir=directory / ".tmp",
        )
        # Extract cookies at construction time, not during fetch_transcripts
        t.extract_cookies(config.accounts[0].storage_state)
        transcriber = t
    return cls(config, registry, raid, transcriber)

# Remove self.transcriber.extract_cookies() call from fetch_transcripts() (line 248)
```

```
Verify: pytest --cov && mypy --strict src
Commit: "refactor: pipeline depends on Protocols, extract_cookies to factory"
```

### W2.3: Deduplicate _find_chrome() (parallel with W2.2)

**New file**: `src/yt_recorder/utils.py`
```python
"""Shared utilities."""
from __future__ import annotations

import platform
import shutil
from pathlib import Path


def find_chrome() -> str:
    """Find Chrome/Chromium executable on the system.

    Returns:
        Path to Chrome executable.

    Raises:
        FileNotFoundError: If no Chrome installation found.
    """
    system = platform.system().lower()
    candidates: list[str] = []

    if system == "darwin":
        candidates = [
            "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
            "/Applications/Chromium.app/Contents/MacOS/Chromium",
        ]
    elif system == "linux":
        for name in ("google-chrome", "google-chrome-stable", "chromium-browser", "chromium"):
            found = shutil.which(name)
            if found:
                candidates.append(found)
    elif system == "windows":
        candidates = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
        ]

    for path in candidates:
        if Path(path).exists():
            return path

    raise FileNotFoundError(
        "Chrome/Chromium not found. Install Google Chrome.\n"
        "  macOS: brew install --cask google-chrome\n"
        "  Linux: apt install google-chrome-stable\n"
        "  Windows: https://google.com/chrome"
    )
```

**youtube.py**: Delete `_find_chrome()` (lines 24-53), add `from yt_recorder.utils import find_chrome`, replace `_find_chrome()` call at line 87 with `find_chrome()`.

**cli.py**: Delete `_find_chrome()` (lines 215-247), add `from yt_recorder.utils import find_chrome`, replace call at line 294 with `find_chrome()`.

**Test impact**: `tests/test_youtube.py` patches `yt_recorder.adapters.youtube._find_chrome` â€” update to `yt_recorder.utils.find_chrome`.

```
Verify: pytest --cov && mypy --strict src
Commit: "refactor: deduplicate find_chrome into utils module"
```

---

## Wave 3 â€” TranscriptStatus Enum + Registry v2

> **Detailed line-by-line plan from Sub-Prometheus session ses_378da46b**

### W3.1: TranscriptStatus enum in models.py

**models.py** changes:
```python
# ADD import:
from enum import Enum

# ADD before RegistryEntry:
class TranscriptStatus(str, Enum):
    """Transcript extraction status."""
    PENDING = "pending"
    DONE = "done"
    UNAVAILABLE = "unavailable"
    ERROR = "error"

# CHANGE RegistryEntry:
#   has_transcript: bool  â†’  transcript_status: TranscriptStatus
# ADD property:
    @property
    def has_transcript(self) -> bool:
        """Backwards-compat: True when transcript done."""
        return self.transcript_status == TranscriptStatus.DONE
```

**Why `str, Enum`**: `TranscriptStatus("pending")` round-trips to/from registry. `isinstance(TranscriptStatus.DONE, str)` is True â€” satisfies Protocol's `status: str`.

```
Commit: "feat: TranscriptStatus enum replaces has_transcript boolean"
```

### W3.2: Registry v2 format + auto-migration

**registry.py** changes (see Wave 3 sub-plan for line-by-line):
- Add `TranscriptStatus` import
- Add `_REGISTRY_VERSION = 2`, `_VERSION_COMMENT`, `_V1_TRANSCRIPT_MAP`
- `update_transcript`: `status: bool` â†’ `status: TranscriptStatus`
- `update_account_id`: `has_transcript=entry.has_transcript` â†’ `transcript_status=entry.transcript_status`
- `_format_row`: `entry.transcript_status.value` instead of emoji
- `_parse_row`: emoji fallback + `TranscriptStatus(raw)` parse + `RegistryParseError` on unknown
- `_create_registry` / `_write_all`: version comment in header

**Migration rules**:
| Input | Output |
|-------|--------|
| âœ… | TranscriptStatus.DONE |
| âŒ | TranscriptStatus.PENDING |
| "pending"/"done"/"unavailable"/"error" | Matching enum |
| Unknown | RegistryParseError |

**Test additions**: 7 new tests in `TestRegistryMigration` class (v1 emoji parse, v2 string parse, unknown raises, auto-upgrade on write).

```
Commit: "feat: registry v2 format with auto-migration from v1"
```

### W3.3: Pipeline + CLI updates

**pipeline.py**:
- Import `TranscriptStatus`
- `upload_new()`: `has_transcript=False` â†’ `transcript_status=TranscriptStatus.PENDING`
- `fetch_transcripts()` filter: `retryable = {PENDING}; if retry: add ERROR; if force: all`
- `fetch_transcripts()` success: `update_transcript(file, TranscriptStatus.DONE)`
- `fetch_transcripts()` TranscriptUnavailableError: `update_transcript(file, TranscriptStatus.UNAVAILABLE)` â† **FIXES infinite retry bug**
- `fetch_transcripts()` generic Exception: `update_transcript(file, TranscriptStatus.ERROR)`

**cli.py**:
- Add `_transcript_icon()` helper: `{DONE: "ðŸ“", PENDING: "â³", UNAVAILABLE: "ðŸš«", ERROR: "âŒ"}`
- Status command: show `[entry.transcript_status.value]` + icon

**Test updates**: Every `RegistryEntry(... False ...)` in test_pipeline.py and test_registry.py â†’ `TranscriptStatus.PENDING` or `.DONE`.

```
Verify: pytest --cov && mypy --strict src
Commit: "feat: pipeline uses TranscriptStatus, fixes infinite retry bug"
```

---

## Wave 4 â€” Clean Command

### W4.1: CleanReport model + pipeline.clean_synced()

**models.py** â€” add:
```python
@dataclass(frozen=True)
class CleanReport:
    """Report from clean_synced() operation."""
    deleted: int = 0
    skipped: int = 0
    errors: list[str] = field(default_factory=list)
    eligible: list[str] = field(default_factory=list)
```

**pipeline.py** â€” add method:
```python
def clean_synced(self, directory: Path, dry_run: bool = False) -> CleanReport:
    """Delete local files fully synced (all accounts + terminal transcript status)."""
    try:
        entries = self.registry.load()
    except RegistryFileNotFoundError:
        return CleanReport()

    terminal = {TranscriptStatus.DONE, TranscriptStatus.UNAVAILABLE}
    account_names = [a.name for a in self.config.accounts]
    deleted = 0
    skipped = 0
    errors: list[str] = []
    eligible: list[str] = []

    for entry in entries:
        path = directory / entry.file
        if not path.exists():
            continue

        # Check all accounts uploaded
        all_uploaded = all(
            entry.account_ids.get(name, "â€”") != "â€”" for name in account_names
        )
        if not all_uploaded:
            skipped += 1
            continue

        # Check transcript terminal
        if entry.transcript_status not in terminal:
            skipped += 1
            continue

        if dry_run:
            eligible.append(entry.file)
            continue

        try:
            path.unlink()
            deleted += 1
        except OSError as e:
            errors.append(f"Failed to delete {entry.file}: {e}")

    return CleanReport(
        deleted=deleted, skipped=skipped, errors=errors, eligible=eligible,
    )
```

```
Commit: "feat: clean_synced deletes fully-synced local files"
```

### W4.2: CLI clean command

**cli.py** â€” add between `status` and `_find_chrome`:
```python
@main.command()
@click.argument(
    "directory", type=click.Path(exists=True, file_okay=False, dir_okay=True, path_type=Path)
)
@click.option("--dry-run", is_flag=True, help="Show what would be deleted")
def clean(directory: Path, dry_run: bool) -> None:
    """Delete local files that are fully synced."""
    from yt_recorder.pipeline import RecordingPipeline

    pipeline = RecordingPipeline.from_directory(directory)
    report = pipeline.clean_synced(directory, dry_run=dry_run)

    if dry_run:
        if report.eligible:
            click.echo(f"Would delete {len(report.eligible)} files:")
            for f in report.eligible:
                click.echo(f"  {f}")
        else:
            click.echo("No files eligible for cleanup")
        return

    click.echo(f"Deleted: {report.deleted}")
    click.echo(f"Skipped: {report.skipped}")
    if report.errors:
        click.echo(f"\nErrors ({len(report.errors)}):")
        for e in report.errors:
            click.echo(f"  - {e}")
```

```
Verify: pytest --cov && mypy --strict src
Commit: "feat: CLI clean command for post-sync file deletion"
```

---

## Wave 5 â€” Playlist Fix

### W5.1: DOM inspection (REQUIRES LIVE SESSION)

```python
# Run interactively with headful Playwright:
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False, executable_path="/path/to/chrome")
    context = browser.new_context(storage_state="path/to/storage_state.json")
    page = context.new_page()
    page.goto("https://studio.youtube.com/video/VIDEO_ID/edit", wait_until="domcontentloaded")
    page.pause()  # Opens Playwright Inspector â€” inspect DOM manually
```

**Look for**:
1. Playlist dropdown trigger (button/link with "Playlist" in aria-label or text)
2. Playlist option elements (checkboxes or list items with playlist names)
3. "New playlist" button
4. Save/Done button for playlist dialog
5. Document full CSS selector path in constants.py comments

**Update constants.py** PLAYLIST_* values with verified selectors.

```
Commit: "fix: update playlist selectors from live YouTube Studio DOM"
```

### W5.2: assign_playlist returns bool + playlist creation

**youtube.py** â€” refactor assign_playlist:
```python
def assign_playlist(self, video_id: str, playlist_name: str) -> bool:
    """Assign video to playlist. Creates if missing. Returns success."""
    if not self.context:
        raise RuntimeError("Browser not opened.")
    page = self.context.new_page()
    try:
        page.goto(
            constants.STUDIO_EDIT_URL.format(video_id=video_id),
            wait_until="domcontentloaded",
        )
        self._check_session_expired(page)
        self._check_bot_detection(page)
        self._random_delay("nav")

        dropdown = page.query_selector(constants.PLAYLIST_DROPDOWN)
        if not dropdown:
            logger.warning("Playlist dropdown not found for %s", video_id)
            return False
        dropdown.click()
        self._random_delay("field")

        option = page.query_selector(
            constants.PLAYLIST_OPTION_TEMPLATE.format(name=playlist_name)
        )
        if not option:
            # TODO: playlist creation flow (needs DOM verification in W5.1)
            logger.warning("Playlist '%s' not found for %s", playlist_name, video_id)
            return False
        option.click()
        self._random_delay("field")

        save = page.query_selector(constants.PLAYLIST_SAVE)
        if not save:
            logger.warning("Save button not found for %s", video_id)
            return False
        save.click()
        self._random_delay("post")
        return True
    finally:
        page.close()
```

**raid.py** â€” capture return value:
```python
playlist_ok = primary_adapter.assign_playlist(primary_result.video_id, playlist)
if not playlist_ok:
    logger.warning("Playlist assignment failed for %s on %s", playlist, self.primary.name)
```

**models.py** â€” add to SyncReport:
```python
playlist_failed: int = 0
```

**Protocol** â€” already defined with `-> bool` in W2.1 âœ“

```
Verify: pytest --cov && mypy --strict src
Commit: "feat: playlist assignment returns bool, tracks failures"
```

---

## Wave 6 â€” Test Coverage

### W6.1: tests/test_cli.py

New file with CliRunner tests for all commands. ~15 test cases.
Mock pattern: `@patch("yt_recorder.cli.RecordingPipeline.from_directory")` â†’ returns Mock pipeline.

### W6.2: Pipeline transcript tests

Add `TestFetchTranscripts` class to test_pipeline.py. 10 test cases covering:
- success â†’ DONE
- TranscriptUnavailableError â†’ UNAVAILABLE (verify registry updated)
- TranscriptNotReadyError â†’ stays PENDING (verify registry NOT updated)
- generic Exception â†’ ERROR
- retry/force flag filtering
- edge cases (no primary, no transcriber, empty registry)

### W6.3: Pipeline clean_synced tests

Add `TestCleanSynced` class. 10 test cases covering:
- all accounts + DONE â†’ deleted
- all accounts + UNAVAILABLE â†’ deleted
- PENDING â†’ skipped
- ERROR â†’ skipped
- missing account â†’ skipped
- file not on disk â†’ skipped
- dry_run â†’ eligible populated
- OSError â†’ error reported
- empty/missing registry â†’ empty report

```
Commit: "test: CLI, transcript, and clean coverage"
```

---

## Wave 7 â€” Future Architecture

### W7.1: StorageBackend protocol

**domain/protocols.py** â€” append:
```python
class StorageBackend(Protocol):
    """Future: destination where videos can be stored and organized.

    YouTubeBrowserAdapter maps: uploadâ†’upload, assign_playlistâ†’assign_collection.
    Implement this for S3, local NAS, Backblaze B2, etc.
    """
    @property
    def name(self) -> str: ...
    def upload(self, path: Path, title: str) -> str: ...
    def assign_collection(self, item_id: str, collection_name: str) -> bool: ...
    def delete_remote(self, item_id: str) -> bool: ...
    def health_check(self) -> bool: ...
```

```
Commit: "feat: StorageBackend protocol for multi-platform extensibility"
```

### W7.2: Health check command

**cli.py** â€” add `health` command checking: config, accounts, chrome, registry, yt-dlp.
Exit code 0/1. No network calls.

```
Commit: "feat: health command for system readiness verification"
```

---

## Wave 8 â€” Content-Hash Dedup + Self-Host Docs

### W8.1: Content-hash dedup

**models.py** â€” add optional field to RegistryEntry:
```python
content_hash: str | None = None  # SHA-256[:16], computed pre-upload
```

**pipeline.py** â€” add `_compute_hash()`, check before upload, store in entry.

**registry.py** â€” optional "Hash" column between Transcript and account columns. Missing â†’ None.

```
Commit: "feat: content-hash dedup prevents duplicate uploads"
```

### W8.2: docs/SELF_HOSTING.md

Architecture overview, StorageBackend examples, registry sync strategies, privacy guarantees.

```
Commit: "docs: self-hosting architecture and extension guide"
```

---

## Wave 9 â€” Open-Source Posture

### W9.1: SECURITY.md
Vulnerability reporting, credential docs, privacy manifest.
```
Commit: "docs: SECURITY.md with privacy manifest"
```

### W9.2: Issue templates
`.github/ISSUE_TEMPLATE/{bug_report.yml, feature_request.yml, config.yml}`.
blank_issues_enabled: false. No PR template.
```
Commit: "chore: issue templates, no-PR posture"
```

### W9.3: README refresh
Architecture diagram, full pipeline, TranscriptStatus, "PRs paused" notice.
```
Commit: "docs: README refresh with architecture + full pipeline"
```

---

## Conflict Resolution (applied during merge)

| Conflict Zone | Resolution |
|---|---|
| RegistryEntry: W3 (transcript_status) + W8 (content_hash) | content_hash is optional with default, goes AFTER account_ids. No conflict â€” W3 changes field 4, W8 appends field 6. |
| Protocols: W2.1 (create) + W5.2 (assign_playlist bool) + W7.1 (StorageBackend) | W2.1 already defines `assign_playlist -> bool`. W7.1 adds new class. Additive. |
| SyncReport: W5.2 (playlist_failed) + W4 (CleanReport separate model) | Different models. No conflict. |
| Pipeline: W3.3 (fetch_transcripts) + W4.1 (clean_synced) + W8.1 (hash in upload_new) | Different methods. No conflict. |
| Registry format: W3.2 (v2 strings) + W8.1 (optional hash column) | Hash column detected by header presence. Backwards-compatible. |
| Constants: W1.2 (move selectors) + W5.1 (update values) | Sequential. W5.1 updates what W1.2 moved. |

## Success Criteria

- [ ] `yt-recorder upload --keep â†’ status â†’ transcribe â†’ clean` works e2e
- [ ] UNAVAILABLE videos never retried (unless --force)
- [ ] Playlist failures surfaced in SyncReport
- [ ] Protocol swap = zero pipeline changes
- [ ] v1 registries auto-upgrade on first load
- [ ] â‰¥85% test coverage (CLI + pipeline transcripts + clean)
- [ ] `mypy --strict src` passes at every commit
- [ ] SECURITY.md, issue templates, no-PR posture in place

## Sub-Prometheus Sessions (for deep implementation detail)

| Wave | Session ID | Status |
|------|-----------|--------|
| W1-2 | ses_378dad0b3ffeu01h8N0QtbY7q1 | line-by-line code |
| W3   | ses_378da46bbffePXGxnV491UppoC | **COMPLETE** â€” 25 constructor sites, 7 migration tests |
| W4-5 | ses_378d9cf4bffeIv1f8ieXXL3uKD | clean impl + DOM strategy |
| W6-7 | ses_378d93c91ffe3gsdl81A6UWRah | full test code + health cmd |
| W8-9 | ses_378d8a51effeR4UI6ehiKB7L6e | hash impl + docs + templates |
