# v0.2 Plan Revision — Security, Performance, Quality

> **Addendum to `v0.2-master-execution.md`. All changes here OVERRIDE the original plan where they conflict.**
> Audit agents: ses_378cc74d (security), ses_378cc385 (performance)

---

## TL;DR

The original plan is solid on architecture/features but has **3 critical security gaps, 1 critical perf bug, and 5 high-severity issues** that weren't addressed. This revision:
- Adds **W0** (security hardening pre-wave) with 4 tasks
- Modifies **W1-W3** to fix registry O(n²) and file locking
- Adjusts **W8** hashing spec for chunked streaming
- **Removes W7.1** (StorageBackend protocol) as premature abstraction
- Adds security constraints to Global Constraints section

Net: +5 tasks, -1 task, ~6h additional effort.

---

## New Global Constraints (append to existing)

### Security
- ALL file paths from registry MUST be validated against base directory (no traversal)
- ALL logger calls with user-controlled data: use %-formatting, NOT f-strings
- Credential files (storage_state.json, cookies.txt): 0o600 after EVERY write
- Registry atomic writes: `os.chmod(0o600)` on tempfile before `os.replace`
- No video IDs or account names in INFO-level logs

### Performance
- Registry mutations: batch where possible, never load-per-update in loops
- File hashing: stream with 64KB chunks, never `file.read()` full content
- Dedup check order: filename first → hash only if new

---

## Wave 0 — Security Hardening (NEW, before W1)

> **Rationale**: These are pre-existing vulnerabilities. Shipping v0.2 features on top would widen the attack surface.

### W0.1: Path traversal guard

**What**: Utility function to validate registry-derived paths stay within base directory.

```python
# utils.py (add alongside find_chrome)
def safe_resolve(base: Path, untrusted: str) -> Path:
    """Resolve untrusted relative path, reject traversal.

    Raises:
        ValueError: If resolved path escapes base directory.
    """
    resolved = (base / untrusted).resolve()
    base_resolved = base.resolve()
    if not resolved.is_relative_to(base_resolved):
        raise ValueError(f"Path traversal blocked: {untrusted!r}")
    return resolved
```

**Apply to**:
- `pipeline.py upload_new()` line 161: `file_path = directory / entry.file` → `safe_resolve(directory, entry.file)`
- `pipeline.py fetch_transcripts()` line 256: `directory / "transcripts" / Path(entry.file)` → validate entry.file
- Plan's `clean_synced()` (W4.1): ALL `directory / entry.file` calls
- `cli.py status()` line 176: `str(path.relative_to(directory))` comparisons

**Acceptance**:
- `safe_resolve(Path("/a"), "../../etc/passwd")` → raises ValueError
- `safe_resolve(Path("/a"), "b/c.mp4")` → returns `/a/b/c.mp4`
- Tests: 4 cases (normal, dotdot, symlink-escape, absolute-in-relative)

```
Commit: "security: path traversal guard for registry-derived paths"
Blocks: W4.1
```

### W0.2: Fix log injection (f-string → %-format)

**What**: Replace all f-string logger calls with lazy %-formatting.

**Files**:
- `pipeline.py:150` → `logger.exception("Upload failed for %s", path)`
- `raid.py:99` → `logger.warning("Mirror %s failed: %s", mirror.name, e)`
- `youtube.py:221,231,239` → `logger.warning("... %s ...", video_id)` (already non-f-string ✓ for line 195)

**Acceptance**: `grep -rn 'logger\.\(warning\|exception\|error\)(f"' src/` returns 0

```
Commit: "security: fix log injection — f-string to lazy format"
```

### W0.3: Credential permission hardening

**What**: Ensure 0o600 on every credential write path.

**Changes**:
1. `youtube.py close()` line 97: After `context.storage_state(path=...)`, add `os.chmod(path, 0o600)`
2. `registry.py _atomic_write()`: Add `os.chmod(temp_path, 0o600)` before `os.replace`
3. `transcriber.py extract_cookies()`: Add `os.chmod(cookies_txt_path, 0o600)` after writing

**Acceptance**: `stat -f '%Lp' <credential_file>` returns `600` after every operation

```
Commit: "security: enforce 0o600 on all credential + registry writes"
```

### W0.4: Document CDP port exposure in setup

**What**: Add warning to `setup` command output + document in SECURITY.md scope (W9.1).

**Changes** (`cli.py` setup command):
```python
click.echo(f"\n⚠️  Chrome CDP debugging port {port} is open during setup.")
click.echo("   Any local process can access your Google session until setup completes.")
click.echo("   Close Chrome immediately after login capture.")
```

Also: `_find_free_port()` already uses random port (good). Add comment documenting why.

```
Commit: "security: warn about CDP port exposure during setup"
```

---

## Wave 1 — Stabilize (REVISED)

### W1.1: Unchanged (commit upload flow fixes)

### W1.2: Unchanged (move playlist selectors to constants.py)

### W1.3: Registry batch update + file locking (NEW)

> **This is the #1 performance fix.** fetch_transcripts() currently does O(n²) registry I/O.

**What**: Add `update_many()` method + `fcntl.flock()` locking to MarkdownRegistryStore.

**registry.py additions**:
```python
import fcntl
from contextlib import contextmanager
from typing import Iterator

@contextmanager
def _locked(self) -> Iterator[None]:
    """Advisory file lock for concurrent access safety."""
    self.registry_path.parent.mkdir(parents=True, exist_ok=True)
    lock_path = self.registry_path.with_suffix(".lock")
    fd = open(lock_path, "w")
    try:
        fcntl.flock(fd, fcntl.LOCK_EX)
        yield
    finally:
        fcntl.flock(fd, fcntl.LOCK_UN)
        fd.close()

def update_many(self, updates: dict[str, dict[str, object]]) -> None:
    """Batch update multiple entries. Single load → mutate → single write.

    Args:
        updates: {filename: {field_name: new_value, ...}, ...}
    """
    with self._locked():
        entries = self.load()
        for i, entry in enumerate(entries):
            if entry.file in updates:
                fields = updates[entry.file]
                kwargs = {
                    "file": entry.file,
                    "playlist": entry.playlist,
                    "uploaded_date": entry.uploaded_date,
                    "has_transcript": fields.get("has_transcript", entry.has_transcript),
                    "account_ids": fields.get("account_ids", entry.account_ids),
                }
                entries[i] = RegistryEntry(**kwargs)
        self._write_all(entries)
```

**Also wrap existing mutators** (`append`, `update_transcript`, `update_account_id`) with `_locked()`.

**Protocol update** (W2.1): Add `update_many` to `RegistryStore` protocol.

**Pipeline refactor** (W3.3): `fetch_transcripts()` collects `{file: TranscriptStatus}` dict, calls `registry.update_many()` once at end.

**Acceptance**:
- `fetch_transcripts()` with 50 entries → exactly 2 registry I/O ops (1 load + 1 write), not 50
- Two concurrent `yt-recorder transcribe` invocations → no data loss (lock serializes)
- Existing `update_transcript()` still works (backwards compat, wraps `update_many`)

```
Commit: "perf: batch registry updates + file locking"
Blocks: W3.3
```

---

## Wave 2 — Foundation (REVISED)

### W2.1: Create domain/protocols.py (REVISED)

**Changes from original**:
- Add `update_many` to `RegistryStore` protocol:
  ```python
  def update_many(self, updates: dict[str, dict[str, object]]) -> None: ...
  ```
- **Remove** `FileScanner` protocol (was in architecture plan, correctly omitted from execution plan)

### W2.2: Unchanged (pipeline depends on Protocols)

### W2.3: Unchanged (deduplicate _find_chrome)

---

## Wave 3 — TranscriptStatus (REVISED)

### W3.1-W3.2: Unchanged

### W3.3: Pipeline + CLI updates (REVISED)

**Critical change**: `fetch_transcripts()` now batch-updates registry.

```python
def fetch_transcripts(self, directory: Path, ...) -> SyncReport:
    entries = self.registry.load()
    entries_needing = [e for e in entries if ...]

    # Collect results, DON'T update registry per-entry
    results: dict[str, TranscriptStatus] = {}

    for entry in entries_needing:
        try:
            # ... fetch logic ...
            results[entry.file] = TranscriptStatus.DONE
        except TranscriptNotReadyError:
            pass  # stays PENDING, not in results
        except TranscriptUnavailableError:
            results[entry.file] = TranscriptStatus.UNAVAILABLE
        except Exception:
            results[entry.file] = TranscriptStatus.ERROR

    # Single batch update
    if results:
        self.registry.update_many({
            f: {"transcript_status": status}
            for f, status in results.items()
        })
```

**Why**: Eliminates O(n²) → O(n). With 50 transcripts: 2 I/O ops instead of 100.

---

## Wave 4 — Clean Command (REVISED)

### W4.1: clean_synced() (REVISED)

**Add** path traversal guard (uses `safe_resolve` from W0.1):
```python
for entry in entries:
    path = safe_resolve(directory, entry.file)  # was: directory / entry.file
    if not path.exists():
        continue
    # ... rest unchanged
```

### W4.2: Unchanged

---

## Wave 7 — Future Architecture (REVISED)

### W7.1: StorageBackend protocol — ~~REMOVED~~ → DEFERRED to v0.3

**Rationale**: Premature abstraction. Zero second implementations exist. Extracting a protocol from a concrete class when needed takes ~1h. Including it now adds interface surface to maintain, test, and document for speculative value.

**What stays**: W7.2 (health check command) — this has concrete immediate value.

### W7.2: Health check command (REVISED)

**Add** to health checks:
- Credential file age warning: if storage_state.json mtime > 7 days, warn "session may expire soon"
- Credential permissions check: verify 0o600 on storage_state.json and cookies.txt

---

## Wave 8 — Content-Hash Dedup (REVISED)

### W8.1: Content-hash dedup (REVISED)

**Performance spec changes**:

1. **Hash algorithm**: SHA-256 with 64KB streaming chunks (never full-file read):
   ```python
   def compute_file_hash(path: Path, chunk_size: int = 65536) -> str:
       h = hashlib.sha256()
       with open(path, "rb") as f:
           while chunk := f.read(chunk_size):
               h.update(chunk)
       return h.hexdigest()[:16]
   ```

2. **Dedup check order**: filename match first (free), hash only if filename is new:
   ```python
   # In upload_new():
   if str(rel_path) in registered_files:
       skipped += 1
       continue
   content_hash = compute_file_hash(path)
   existing = registry.find_by_hash(content_hash)
   if existing:
       logger.info("Duplicate detected: %s matches %s", rel_path, existing.file)
       skipped += 1
       continue
   ```

3. **Store `(hash, file_size)` tuple** — not just hash. Eliminates theoretical second-preimage concern:
   ```python
   # RegistryEntry addition:
   content_hash: str | None = None    # SHA-256[:16]
   file_size_bytes: int | None = None  # for hash collision safety
   ```

4. **Progress feedback for large files**: Hash computation for 500MB takes ~1-2s. If `progress_callback` is set, report hashing phase.

### W8.2: Unchanged (SELF_HOSTING.md)

---

## Wave 9 — Open-Source Posture (REVISED)

### W9.1: SECURITY.md (REVISED)

**Add sections** based on audit findings:
- CDP port exposure during setup (C3)
- storage_state.json trust model
- cookies.txt lifecycle (created in tmpdir, copied to config dir, 0o600)
- Path traversal protections
- Log sanitization policy
- "What data leaves your machine" (already planned)

### W9.2-W9.3: Unchanged

---

## Revised Execution Order

```
W0.1 → W0.2 + W0.3 + W0.4 (parallel)
          ↓
**W1.1** → **W1.2** + **W1.3** (parallel)
                          ↓
              **W2.1** → W2.2 + W2.3 (parallel)
                           ↓
                       **W3.1** → **W3.2** → **W3.3** (uses batch update)
                                                ↓
                                    **W4.1** → **W4.2** → W5.1 → W5.2
                                                              ↓
                                                W6.1 + W6.2 + W6.3 (parallel)
                                                              ↓
                                                            W7.2
                                                              ↓
                                                      W8.1 + W8.2 (parallel)
                                                              ↓
                                                W9.1 + W9.2 + W9.3 (parallel)
```

**Changes from original**:
- W0 prepended (security hardening)
- W1.3 added (batch update + locking)
- W7.1 removed (StorageBackend deferred)
- W3.3 depends on W1.3 (batch update)

---

## Summary of All Findings

### Security (from audit ses_378cc74d + own analysis)

| ID | Severity | Issue | Fix | Wave |
|----|----------|-------|-----|------|
| C1 | CRITICAL | No storage_state.json validation | Schema validate on load | W0 (backlog) |
| C2 | CRITICAL | Path traversal via registry entries | `safe_resolve()` guard | **W0.1** |
| C3 | CRITICAL | CDP port exposure during setup | Warning + docs | **W0.4** |
| H1 | HIGH | Log injection via f-string | %-formatting | **W0.2** |
| H2 | HIGH | Credential permissions reset on rewrite | chmod after every write | **W0.3** |
| H3 | HIGH | No integrity check on storage_state | HMAC (optional) | Backlog |
| H4 | HIGH | SHA-256 dedup without file size | Store (hash, size) tuple | **W8.1** |
| M1 | MEDIUM | cookies.txt readable by yt-dlp | Tmpdir + immediate delete | Backlog |
| M2 | MEDIUM | No credential rotation/expiry | Age check in health cmd | **W7.2** |
| M3 | MEDIUM | executable_path not validated | Location check | Backlog |
| M4 | MEDIUM | Atomic writes don't set permissions | chmod on tempfile | **W0.3** |

### Performance (from audit ses_378cc385 + own analysis)

| ID | Severity | Issue | Fix | Wave |
|----|----------|-------|-----|------|
| P1 | CRITICAL | O(n²) registry in fetch_transcripts | Batch update_many() | **W1.3** |
| P2 | CRITICAL | No file locking on registry | fcntl.flock() | **W1.3** |
| P3 | HIGH | SHA-256 of 500MB+ naive read | 64KB chunked streaming | **W8.1** |
| P4 | HIGH | Full load for single lookup | In-memory cache per invocation | Backlog |
| P5 | HIGH | Sync browser = sequential uploads | Async Playwright (v0.3) | Deferred |
| P6 | MEDIUM | sleep() blocks thread | Acceptable for v0.2 | Deferred |
| P7 | MEDIUM | StorageBackend premature abstraction | **Removed from plan** | — |

### Engineering Quality (own analysis)

| ID | Severity | Issue | Fix | Wave |
|----|----------|-------|-----|------|
| Q1 | HIGH | SyncReport overloaded for upload+transcript | Acceptable, revisit v0.3 | Deferred |
| Q2 | HIGH | No transcriber.cleanup() call | Add to fetch_transcripts finally block | **W3.3** |
| Q3 | MEDIUM | Config is mutable dataclass | Freeze it | Backlog |
| Q4 | MEDIUM | "—" sentinel in account_ids | Type-safe Optional | Backlog |
| Q5 | LOW | _format_separator recomputes column list | Minor, ignore | — |

---

## Deferred to v0.3 (backlog)

1. storage_state.json schema validation (C1) — needs design for what valid schema looks like
2. HMAC integrity on storage_state (H3) — optional hardening
3. cookies.txt tmpdir lifecycle (M1) — needs yt-dlp API investigation
4. executable_path validation (M3) — low attack surface
5. Registry in-memory cache (P4) — YAGNI until 1000+ entries
6. Async Playwright for parallel uploads (P5) — major refactor
7. StorageBackend protocol (P7) — extract when second backend exists
8. SyncReport split into UploadReport/TranscriptReport (Q1)
9. Config frozen dataclass (Q3)
10. Type-safe account_ids (Q4)
